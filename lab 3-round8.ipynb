{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13570a7-cd43-4d8b-a323-0f44e160af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4ba357-c586-4a94-811d-c8abe2d5bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2fda1a-28f7-45ad-9301-12ec96880371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4008, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb75c4f-349f-48e4-81e2-edbf2f95c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "number_of_open_complaints\n",
       "1/0/00    830\n",
       "1/1/00    138\n",
       "1/2/00     50\n",
       "1/3/00     34\n",
       "1/4/00     13\n",
       "1/5/00      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(df):\n",
    "    #columns appear to be categorical: ST Gender Education Policy type Vehicle Class\n",
    "    cols = []\n",
    "    for colname in df.columns:\n",
    "        cols.append(colname.lower())\n",
    "    df.columns = cols\n",
    "    # Replace white spaces in column names with underscores\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    # Replace 'st' with 'state' in column names\n",
    "    df= df.rename({'st': 'state'}, axis=1)\n",
    "    # Clean Gender column\n",
    "    char_to_replace = {\"femal\": 'F', 'male': 'M', \"female\": \"F\", \"Fe\": \"F\", \"Fmal\": \"F\", \"Male\": \"M\"}\n",
    "    # Iterate over all key-value pairs in dictionary \n",
    "    for key, value in char_to_replace.items():\n",
    "        # Replace key character with value character in string\n",
    "        df['gender'] = df['gender'].str.replace(key, value)\n",
    "    # Clean State column\n",
    "    df['state'].value_counts()\n",
    "    state_mapping = {'AZ': 'Arizona','Californiaforniaforniaforniafornia': 'California',  'Californiaforniaforniaforniaforniafornia': 'California', 'Cali': 'California', 'Californiafornia': 'California', 'WA': 'Washington'}\n",
    "    for key, value in state_mapping.items():\n",
    "        # Replace key character with value character in string\n",
    "        df['state'] = df['state'].str.replace(key, value)\n",
    "    # Clean education column\n",
    "    df['education'].value_counts()\n",
    "    df[\"education\"] = df['education'].str.replace(\"Bachelors\", \"Bachelor\")\n",
    "    # Clean Customer Lifetime Value column\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].str.rstrip('%')\n",
    "    # Clean Vehicle Class column\n",
    "    vehicle_class_mapping = {'Sports Car': 'Luxury', 'Luxury SUV': 'Luxury', 'Luxury Car': 'Luxury'}\n",
    "    # Iterate over all key-value pairs in dictionary \n",
    "    for key, value in vehicle_class_mapping.items():\n",
    "        # Replace key character with value character in string\n",
    "        df['vehicle_class'] = df['vehicle_class'].str.replace(key, value)\n",
    "    # Customer lifetime value should be numeric\n",
    "    df['customer_lifetime_value'] = pd.to_numeric(df['customer_lifetime_value'], errors='coerce')\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].astype(float)\n",
    "    # Number of open complaints has an incorrect format.\n",
    "    df[\"number_of_open_complaints\"].value_counts()\n",
    "    # Extract the number of open complaints from each entry and calculate the middle value\n",
    "    df['number_of_open_complaints'] = df['number_of_open_complaints'].str.split('/').str[1]\n",
    "    # Cast the column to the proper numeric type\n",
    "    df['number_of_open_complaints'] = pd.to_numeric(df['number_of_open_complaints'], errors='coerce')\n",
    "    df['number_of_open_complaints'] = df['number_of_open_complaints'].astype(float)\n",
    "    round(df.isna().sum()/len(df),4)*100  # shows the percentage of null values in a column\n",
    "    nulls_df = pd.DataFrame(round(df.isna().sum()/len(df),4)*100)\n",
    "    nulls_df = nulls_df.reset_index()\n",
    "    nulls_df.columns = ['header_name', 'percent_nulls']\n",
    "    # Fill null values with column mean for numerical variables\n",
    "    column_categorical=[\"state\", \"gender\", \"education\", \"policy_type\", \"vehicle_class\"]\n",
    "    column_numerical=[\"income\", \"monthly_premium_auto\", \"total_claim_amount\", \"customer_lifetime_value\", \"number_of_open_complaints\"]\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])\n",
    "    # Step 1: Identify duplicate rows\n",
    "    duplicates = df.duplicated()\n",
    "    df= df.drop_duplicates(keep='first') #to not lose more data, I prefer to keep the first duplicate.\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "# Step 6: Save the cleaned dataset to a new CSV file\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "cleaning(df)\n",
    "#print(df.dtypes)\n",
    "# df[\"number_of_open_complaints\"].value_counts()\n",
    "# print(df.shape)\n",
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1e18-3c94-4bb3-b3f9-8d2be475d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.describe().T\n",
    "def roundforme(x):\n",
    "    return round(x,2)\n",
    "\n",
    "summary['mean'] = list(map(roundforme, summary['mean']))\n",
    "\n",
    "# summary\n",
    "for col in summary.columns:\n",
    "    summary[col] = summary[col].apply(lambda x : round(x, 2))\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2730d-013f-4e38-85c9-290d12777e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387fcac-91b0-43eb-8462-0d11bbc6a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['monthly_premium_auto'].unique()\n",
    "for i, x in enumerate(df['monthly_premium_auto']):\n",
    "    if x > 400:\n",
    "        df.at[i, 'monthly_premium_auto'] =193.23436\n",
    "df['monthly_premium_auto'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9037f-b137-4962-a239-49a2e0131020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be54635-9f3c-4567-969e-a3ec4c1f2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a160e-03cb-4c78-8c60-ee32a0ffaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed9cf8-5439-4b1e-ac25-f310af5f8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install seaborn if you need to\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "# Task 3: Show a plot of the Gender breakdown\n",
    "gender_counts = df['gender'].value_counts()\n",
    "gender_counts.plot(kind='bar', color=['blue', 'pink'])\n",
    "plt.title('Gender Breakdown')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "#The number of females is higher than males with over 620 F comparing to 452 M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931561c-65da-40c2-8bdf-a3ade2528ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything can be a bar chart, but that is a sad sad world\n",
    "sns.barplot(x=\"state\", y=\"income\", data=df)\n",
    "\n",
    "# Adjust the font size of the state value labels\n",
    "plt.xticks(fontsize=8) \n",
    "plt.title('Income by state')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Income')\n",
    "plt.show()\n",
    "# individuals in Washington make more income than any other place while Nevada makes the least "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4883c9-3c19-4af4-8d9d-96ce995aa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca79fe-3db9-4ff0-968f-464b7b790b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything can be a bar chart, but that is a sad sad world\n",
    "sns.barplot(x=\"policy_type\", y=\"total_claim_amount\", data=df)\n",
    "\n",
    "# Adjust the font size of the state value labels\n",
    "plt.xticks(fontsize=10) \n",
    "plt.title('Policy type by total claim amount')\n",
    "plt.xlabel('Policy type')\n",
    "plt.ylabel('Total claim amount')\n",
    "plt.show()\n",
    " # People with corporate autos have total claim the most and spacial autos has the least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a68e3b-80da-4904-9676-4522e1db0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "sns.countplot(x=\"education\", hue=\"vehicle_class\", data=df)\n",
    "plt.title('Education by Vehicle Class')\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "# Show the plot\n",
    "plt.legend(title='Vehicle Class', bbox_to_anchor=(1.05, 1), loc='upper left')  # Adjust legend position\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()\n",
    "\n",
    "#the majority of individuals no mater their education level have four-door cars with the people who have a Bachelor degrees score \n",
    "# the highest at over 175 and people with a doctoral degree score the least at 20. While luxury cars are hard to get for all groups of \n",
    "# different educational levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01835e3b-7344-4173-9a07-22bd2f31a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What other plots do you feel would be beneficial?\n",
    "# state vs total_claim_amount to see which states are complaining the most\n",
    "# education vs income to see which groups make more income\n",
    "# gender vs income to look at the income gap\n",
    "# gender vs vehicle_class to see the gap \n",
    "# gender vs total_claim_amount to see which gender is complaining the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cfaca-bf17-4324-a7c3-3f63c64a0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include=np.number)\n",
    "categorical = df.select_dtypes(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcfd7b-d333-49ee-a5b9-bd4808082d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f68560-220b-4119-9c81-7036e604e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in numerical:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(data=df, x=var, kde=True, color='skyblue', bins=30)\n",
    "    plt.title(f'Distribution of {var}')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363dd025-d499-4af6-ad7b-ea8b2bd60ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in numerical:\n",
    "    plt.figure(figsize=(8, 6))  # Adjust figure size as needed\n",
    "    plt.hist(df[var], bins=30, color='skyblue', edgecolor='black')  \n",
    "    plt.title(f'Histogram of {var}')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80770d7-dc8c-418e-a664-0514c0ee1f3f",
   "metadata": {},
   "source": [
    "==> Total claim amounts + monthly premium auto looks like normal distribution skewed to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b0f0c-23ff-475f-9a76-85fb55d149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_matrix = numerical.corr()\n",
    "sns.heatmap(correlations_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303c1e9-882b-4a3d-b7ed-801d12f453d8",
   "metadata": {},
   "source": [
    "==> it looks fine to me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b148bb1-7534-4605-9c17-d3dd0ad953fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['total_claim_amount']\n",
    "X = df.drop(['total_claim_amount'], axis=1)\n",
    "\n",
    "X_num = df.select_dtypes(include = np.number)\n",
    "X_cat = df.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818fc23-3d44-4d44-ae94-9ac5e6b62fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8616d6c-1eb3-4f29-97c0-d1a0ebeb6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat\n",
    "X_cat.drop(columns=\"customer\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d598653-fd1a-41d3-9871-a6d35b5824f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling standard scaler: make data distributed with mean=0 and std=1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler().fit(X_num)\n",
    "X_standardized = transformer.transform(X_num)\n",
    "print(X_standardized.shape)\n",
    "X_standardized = pd.DataFrame(X_standardized,columns=X_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93339007-290c-4992-8708-dfe941ab04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding is a way to turn categorical variables into multiple numerical columns\n",
    "encoder = OneHotEncoder(drop='first').fit(X_cat)\n",
    "print(encoder.categories_)\n",
    "encoded = encoder.transform(X_cat).toarray()\n",
    "print(encoded)\n",
    "onehot_encoded = pd.DataFrame(encoded,columns=['California', 'Nevada', 'Oregon', 'Washington', 'M', 'College', 'Doctor', 'High School or Below', 'Master', 'Personal Auto', 'Special Auto', 'Luxury', 'SUV', 'Two-Door Car'])\n",
    "onehot_encoded.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f08f8f-1cb7-4bf2-8e8b-93574a05e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's merge all this information together into a single dataset with all features\n",
    "X1 = pd.concat([X_standardized, onehot_encoded ], axis=1)  # np.concatenate()\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4444e-ea15-4ebd-97f7-8792505685dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X1.drop(['total_claim_amount'], axis=1)\n",
    "y = X1['total_claim_amount']\n",
    "y.head()\n",
    "# train test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c01c07-9c59-4c80-b18e-7b370d35208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596a102-87ff-42d1-ac87-e760559995ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train/fit our model \n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041117ee-185b-44d6-b15e-089f17d0b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa128c-1537-4ab6-bc1a-de772090abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c310310-8ed3-4661-a2e9-2b2d1a26a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45709f1-73ec-4b60-9771-fbad540cfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "rmse\n",
    "rmse = math.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218d2a3-1c3c-4e39-b001-4486fd32219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, predictions_test)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ece6e-5549-464a-ab5f-3aad514c7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079b2fa-9111-4e6d-940e-b5d726d2f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, predictions_test)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381b021-24b1-4a5c-a3ad-d4a654a8df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some approaches you can try in this exercise:\n",
    "# use the concept of multicollinearity and remove insignificant variables\n",
    "# use a different method of scaling the numerical variables\n",
    "# use a different ratio of train test split\n",
    "# use the transformation on numerical columns which align it more towards a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb224af-0275-45cd-805b-351efe72c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X1.drop(['total_claim_amount', 'number_of_open_complaints'], axis=1)\n",
    "y = X1['total_claim_amount']\n",
    "y.head()\n",
    "# train test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4c526-deec-4f8b-9f02-840030e2cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train/fit our model \n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8e0a1-2b75-4023-8965-51f5ad4aa8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384ce4c-e33e-4066-b936-c5af53212baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c5344-9c9a-4519-820a-be93f669b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change strategy to improve the model\n",
    "transformer = MinMaxScaler().fit(X_num)\n",
    "X_norm = transformer.transform(X_num)\n",
    "print(X_norm.shape)\n",
    "X_num_scale = pd.DataFrame(X_norm, columns=X_num.columns)\n",
    "X_num_scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d2108-ab08-49f8-ab69-15e34fc2ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's merge all this information together into a single dataset with all features\n",
    "X1 = pd.concat([X_num_scale, onehot_encoded ], axis=1)  # np.concatenate()\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c10ab-07c5-450f-8281-2135cb2c1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X1.drop(['total_claim_amount', 'number_of_open_complaints'], axis=1)\n",
    "y = X1['total_claim_amount']\n",
    "y.head()\n",
    "# train test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=90)\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "predictions = lm.predict(X_train)\n",
    "r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab583a95-d7b9-4aac-96e7-3e4f5c134d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = lm.predict(X_test)\n",
    "r2_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34064e8e-0f81-42a3-acce-cba810bf7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,predictions_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ff96f-651d-4a79-98bb-8174a9f5838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "rmse\n",
    "rmse = math.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2231894d-19bd-432a-9c69-6fa43d61b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final results show an R2 of 0.58 for the trained model and 0.44 for the predicted model. MSE is equal to 0.006 and RMSE= 0.077"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
